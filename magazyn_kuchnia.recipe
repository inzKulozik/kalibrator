#!/usr/bin/env python

__license__ = 'GPL v3'

from calibre.web.feeds.news import BasicNewsRecipe
import datetime

class forbes_pl(BasicNewsRecipe):
    title = u'Magazyn Kuchnia'
    __author__ = 'Artur Stachecki <artur.stachecki@gmail.com>'
    language = 'pl'
    description = u'Kuchnia - magazyn dla smakoszy! Przepisy kulinarne, gotowanie, felietony i kulinarne podróże.'
    max_articles_per_feed = 100
    remove_javascript = True
    no_stylesheets = True
    now = datetime.datetime.now()
    yesterday = now - datetime.timedelta(days=7)
    yesterday = yesterday.strftime("%d.%m.%Y")
    pages_count = 5
    simultaneous_downloads = 5
    cover_url = 'http://www.kiosk24.pl/img/_covers/191/static/424x600.jpg'
    masthead_url = 'http://bi.gazeta.pl/im/5/11969/m11969205.jpg'

    extra_css = '''       img { display: block; margin-right: auto;}
                        h1 {text-align: left; font-size: 22px;}'''

    def parse_index(self):
        feeds = []
        for title, url in [('Najnowsze artykuły', 'http://magazyn-kuchnia.pl/magazyn-kuchnia')
                           ]:
            articles = self.parse_pages(url)
        if articles:
            feeds.append((title, articles))
        return feeds

    def parse_pages(self, pages):
        second = self.get_pages(pages)
        current_articles = []
        for soup in second:
            div = soup.find(attrs={'class': 'body'})
            for tag in div.findAllNext('li', attrs={'class': re.compile(r'article$')}):
                link = tag.find('h3')
                a = link.find('a', href=True)
                if a is None:
                    continue
                title = self.tag_to_string(a)
                url = a.get('href', False)
                if not url or not title:
                    continue
                if url.startswith('/'):
                    url = 'http://magazyn-kuchnia.pl' + url
                current_articles.append({'title': title,
                                         'url': url, 'description': '', 'date': ''})
        return current_articles

    def get_pages(self, url):
        soup = self.index_to_soup(url)
        apage = soup.find('div', attrs={'class': 'pages'})
        pages = [soup]
        for n in range(2, self.pages_count):
            if apage is not None:
                nexturl = soup.find(
                    'a', attrs={'href': re.compile(r'.*str=%s.*8' % (n))})
                nexturl = 'http://magazyn-kuchnia.pl' + nexturl['href']
                nextsoup = self.index_to_soup(nexturl)
                pages.append(nextsoup)
        return pages

    def preprocess_html(self, soup):
        date = soup.find(attrs = {'id': 'gazeta_article_date'})
        date = self.tag_to_string(date)
        date = date.split(",")[0]
        date = date.replace(' ', '')
        if (date < self.yesterday):
            return None
        else:
            printer = soup.find(attrs={'alt': 'Drukuj'})
            if printer is None:
                return None
            else:
                self.append_page(soup, soup.body)
                classes = soup.findAll(attrs = {'class' : [ 'prev', 'next', 'page', 'sitePath_wrap', 'content_row']})
                ids = soup.findAll(attrs = {'id': ['gazeta_article_likes', 'gazeta_article_author', 'gazeta_article_date', 'gazeta_article_tools', 'gazeta_article_lead', 'gazeta_article_tags', 'gazeta_article_share', 'banP4', 'article_toolbar', 'page-hat', 'pageHead', 'navtop_wrap', 'navH', 'col_right', 'banP62', 'footer', 'gazeta_article_lead']})
                for tag in ids:
                    tag.replaceWith('')
                for tag in classes:
                    tag.replaceWith('')
                return soup

    def append_page(self, soup, appendtag):
        pager = soup.find('div', attrs={'class':'navigation'})
        if pager:
            a = pager.find('a', attrs = {'class' : 'next'})
            a_prev = pager.find('a', attrs = {'class' : 'prev'})
            if a:
                nexturl = a['href']
                soup2 = self.index_to_soup(nexturl)
                pagetext = soup2.find('div', attrs = {'id' : 'gazeta_article'})
                section_title = soup2.find(attrs = {'class' : 'artTitle'})
                article_title = pagetext.find('h1')
                article_lead = pagetext.find(attrs = {'id' : 'gazeta_article_lead'})
                article_image = pagetext.find(attrs = {'id' : 'gazeta_article_image'})
                article_content = pagetext.find(attrs = {'id' : 'gazeta_article_body'})
                one_more = soup2.find('a', attrs={'class':'see-one-more-time'})
                if one_more is None:
                    if 'Polecamy' in a_prev['href']:
                        for first_page_content in [section_title, article_lead]:
                            first_page_content.extract()
                            pos = len(appendtag.contents)
                            appendtag.insert(pos, first_page_content)

                    for content in [article_title, article_image, article_content]:
                        content.extract()
                        pos = len(appendtag.contents)
                        appendtag.insert(pos, content)

                    self.append_page(pagetext, appendtag)
        else:
            pagetext = soup.find('div', attrs = {'id' : 'gazeta_article'})
            section_title = soup.find(attrs = {'class' : 'artTitle'})
            article_title = pagetext.find('h1')
            article_lead = pagetext.find(attrs = {'id' : 'gazeta_article_lead'})
            article_image = pagetext.find(attrs = {'id' : 'gazeta_article_image'})
            article_content = pagetext.find(attrs = {'id' : 'gazeta_article_body'})
            for content in [section_title, article_title, article_image, article_content]:
                content.extract()
                pos = len(appendtag.contents)
                appendtag.insert(pos, content)
