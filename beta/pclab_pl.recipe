#!/usr/bin/env  python

__license__   = 'GPL v3'
__copyright__ = u'2010, Richard forum_eksiazki_org'
'''pclab.pl'''

from calibre.web.feeds.news import BasicNewsRecipe

class PCLab_pl(BasicNewsRecipe):
    title          = u'PCLab.pl'
    publisher      = u'PCLab.pl'
    description    = u'PCLab.pl - aktualno\u015bci i artyku\u0142y'
    language = 'pl'
    __author__ = 'Richard forum_eksiazki_org'
    oldest_article = 7
    max_articles_per_feed = 50
    no_stylesheets = True
    remove_javascript = True

#feeds          = [(u'PCLab.pl - aktualno\u015bci', u'http://pclab.pl/xml/aktualnosci.xml')]
    feeds          = [(u'PCLab.pl - Artyku\u0142y', u'http://pclab.pl/xml/artykuly.xml')]

    keep_only_tags = [dict(name='div', attrs={'class':'substance'})]

    remove_tags = [
        dict(name='div', attrs={'class':'tags'}),
        dict(name='div', attrs={'class':'navigation'}),
        dict(name='div', attrs={'class':'zumi'}),
        dict(name='div', attrs={'class':'chapters'}),
        dict(name='div', attrs={'class':'index'})
]

    remove_attributes = ['width', 'height']

    extra_css = '''h1 { font-size: 1.4em; }
                        h2 { font-size: 1.0em; }'''

    def append_page(self, soup, appendtag, position):
        pager = soup.find('div',attrs={'class':'next'})
        if pager:
           print 'jest!'
           nexturl = pager.a['href']
           soup2 = self.index_to_soup(nexturl)
           texttag = soup2.find('div', attrs={'class':'data'})
           newpos = len(texttag.contents)
           self.append_page(soup2,texttag,newpos)
           texttag.extract()
           appendtag.insert(position,texttag)

    def preprocess_html(self, soup):
        mtag = '<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-2" />'
        soup.head.insert(0,mtag)
        self.append_page(soup, soup.body, 3)
        pager = soup.find('div',attrs={'class':'navigation'})
        if pager:
           pager.extract()
        return soup

