import re

from calibre.web.feeds.news import BasicNewsRecipe

class KrytykaPolitycznaRecipe(BasicNewsRecipe):
    __license__ = 'GPL v3'
    __author__ = u'intromatyk <intromatyk@gmail.com>'
    language = 'pl'
    version = 1

    title = u'Krytyka Polityczna'
    category = u'News'
    description = u' Lewicowe pismo zaanga≈ºowane w bieg spraw publicznych w Polsce.'
    cover_url=''
    remove_empty_feeds= True
    no_stylesheets=True
    oldest_article = 7
    max_articles_per_feed = 100000
    recursions = 0

    no_stylesheets = True
    remove_javascript = True
    simultaneous_downloads = 3

    keep_only_tags =[]
    keep_only_tags.append(dict(name = 'td', attrs = {'class' : 'contentheading'}))
    keep_only_tags.append(dict(name = 'td', attrs = {'valign' : 'top'}))

    remove_tags =[]
    remove_tags.append(dict(name = 'ul'))
    remove_tags.append(dict(name = 'h3'))
    remove_tags.append(dict(name = 'div', attrs = {'id' : 'comment'}))
    remove_tags.append(dict(name = 'img'))
    remove_tags.append(dict(name = 'td', attrs = {'valign' : 'top', 'align' : 'left'}))
    remove_tags.append(dict(name = 'td', attrs = {'class' : 'createdate'}))

    extra_css = '''
                    body {font-family: verdana, arial, helvetica, geneva, sans-serif ;}
                    td.contentheading{font-size: large; font-weight: bold;}
                    '''    

    feeds          = [
                            ('Publicystyka', 'http://feeds.feedburner.com/KrytykaPolityczna-Publicystyka'),
                            ('Felietony', 'http://feeds.feedburner.com/KrytykaPolityczna-Felietony'),
                            ('Newsy', 'http://feeds.feedburner.com/NewsyKrytykiPolitycznej'),
                            ('Zaproszenia', 'feed://feeds.feedburner.com/KrytykaPolityczna-Zaproszenia'),
                            ('Kluby KP', 'feed://feeds.feedburner.com/KrytykaPolityczna-KlubyKp'),
                            ('Wydawnictwo KP', 'feed://feeds.feedburner.com/WydawnictwoKrytykiPolitycznej'),
                          ]
    
    def preprocess_html(self, soup):
        for alink in soup.findAll('a'):
            if alink.string is not None:
               tstr = alink.string
               alink.replaceWith(tstr)
        return soup
